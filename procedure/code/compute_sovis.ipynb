{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0678297c-b061-48dc-b866-8481a458eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/usr/bin/env\n",
    "\n",
    "# This file calculates and exports five files\n",
    "# US_Sovi_Score = a sovi analysis using the entire us outputs county score and rank\n",
    "# FEMA_Region_Sovi_Score = a sovi analysis by fema region outputs county score and rank\n",
    "# State_Sovi_Score = a sovi analysis by state for 10 states outputs county score and rank\n",
    "# county_in_state_rank = a ranking of the counties of 10 states from the us, region level, and state level analysis\n",
    "# variable_contributions = net contributions of each variable in each\n",
    "# analysis above\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "# import geopandas as gpd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "sys.path.insert(1, \"./code\")\n",
    "from spss_pca import SPSS_PCA\n",
    "from drop1_place import *\n",
    "import data_prep\n",
    "pd.set_option(\"chained_assignment\", None)\n",
    "\n",
    "path=os.getcwd()\n",
    "outPath = os.path.join(path, 'data')\n",
    "ipath = os.path.join(path, 'data', 'input')\n",
    "spath = os.path.join(path, 'data', 'spatial')\n",
    "\n",
    "# copy db1 to new varname for clarity\n",
    "US_All = data_prep.db1.copy()\n",
    "US_All['Geo_FIPS'] = US_All.index.values\n",
    "\n",
    "\n",
    "# attribute name and expected influence on vulnerability\n",
    "input_names = [['MEDAGE_ACS', 'pos', 'person', 'Median Age'],\n",
    "               ['BLACK_ACS', 'pos', 'person', 'Pop African-American (%)'],\n",
    "               ['QNATAM_ACS', 'pos', 'person', 'Pop Native American (%)'],\n",
    "               ['QASIAN_ACS', 'pos', 'person', 'Pop Asian (%)'],\n",
    "               ['QHISP_ACS', 'pos', 'person', 'Pop Hispanic (%)'],\n",
    "               ['QAGEDEP_ACS', 'pos', 'person', 'Age Dependency (%)'],\n",
    "               ['QPUNIT_ACS', 'pos', 'person', 'Persons Per Housing Unit'],\n",
    "               ['PRENTER_ACS', 'pos', 'hu', 'Rental Housing (%)'],\n",
    "               ['QNRRES_ACS', 'pos', 'person', 'Nursing Home Residents (%)'],\n",
    "               ['QFEMALE_ACS', 'pos', 'person', 'Pop Female (%)'],\n",
    "               ['QFHH_ACS', 'pos', 'hu', 'Female-Headed Households (%)'],\n",
    "               ['QUNOCCHU_ACS', 'pos', 'hu', 'Vacant Housing (%)'],\n",
    "               ['PERCAP_ALT', 'neg', 'person', 'Per-Capita Income'],\n",
    "               ['QESL_ALT', 'pos', 'person', 'English as Second Language (%)'],\n",
    "               ['QCVLUN', 'pos', 'person', 'Unemployment (%)'],\n",
    "               ['QPOVTY', 'pos', 'person', 'Poverty (%)'],\n",
    "               ['QMOHO', 'pos', 'hu', 'Mobile Homes (%)'],\n",
    "               ['QED12LES_ALT', 'pos', 'person',\n",
    "                   'Adults Completed <Grade 12 (%)'],\n",
    "               ['QFEMLBR', 'pos', 'person', 'Female Employment (%)'],\n",
    "               ['QEXTRCT_ALT', 'pos', 'person',\n",
    "                   'Extractive Sector Employment (%)'],\n",
    "               ['QSERV_ALT', 'pos', 'person', 'Service Sector Employment (%)'],\n",
    "               ['QSSBEN', 'pos', 'hu', 'Social Security Income (%)'],\n",
    "               ['QNOAUTO_ALT', 'pos', 'hu', 'No Automobile (%)'],\n",
    "               ['QFAM', 'neg', 'person', 'Children in Married Families (%)'],\n",
    "               ['QRICH200K', 'neg', 'hu', 'Annual Income >$200K (%)'],\n",
    "               ['MDGRENT_ALT', 'neg', 'hu', 'Median Rent'],\n",
    "               ['MHSEVAL_ALT', 'neg', 'hu', 'Median Home Value'],\n",
    "               ['POPDENS', 'pos', 'person', 'Population Density']]\n",
    "\n",
    "# Get attribute names\n",
    "attr_names = [j[0] for j in input_names]\n",
    "# cols = [c for c in US_All.columns if c.find('_SE') == -1]\n",
    "\n",
    "attr_names.append('Geo_FIPS')\n",
    "# US_All = US_All.dropna(axis=0) #two counties misisng data in state 15 and 48\n",
    "US_All = US_All[attr_names]\n",
    "US_All['stateID'] = US_All.Geo_FIPS.str.slice(0, 3, 1)\n",
    "attr_names.remove('Geo_FIPS')\n",
    "\n",
    "# ####Flipping Signs\n",
    "# To ensure that each variable contributes as expected to the final Sovi\n",
    "# Index following Eric Tate (2012?) we flip the signs of the input data.\n",
    "for name, sign, sample, hrname in input_names:\n",
    "    if sign == 'neg':\n",
    "        US_All[name] = -US_All[name].values\n",
    "    elif sign == 'pos':\n",
    "        pass\n",
    "    else:\n",
    "        print(\"problem in flipping signs\")\n",
    "        raise\n",
    "\n",
    "# Build FEMA subRegions Dict values= state ID's\n",
    "FEMA_subs = dict()\n",
    "FEMA_subs['FEMA_1'] = ['g23g33g25', 'g50', 'g09', 'g44']\n",
    "FEMA_subs['FEMA_2'] = ['g36', 'g34']\n",
    "FEMA_subs['FEMA_3'] = ['g42', 'g10', 'g11', 'g24', 'g51', 'g54']\n",
    "FEMA_subs['FEMA_4'] = ['g21', 'g47', 'g37', 'g28', 'g01', 'g13', 'g45', 'g12']\n",
    "FEMA_subs['FEMA_5'] = ['g27', 'g55', 'g26', 'g17', 'g18', 'g39']\n",
    "FEMA_subs['FEMA_6'] = ['g35', 'g48', 'g40', 'g05', 'g22']\n",
    "FEMA_subs['FEMA_7'] = ['g31', 'g19', 'g20', 'g29']\n",
    "FEMA_subs['FEMA_8'] = ['g30', 'g38', 'g56', 'g46', 'g49', 'g08']\n",
    "FEMA_subs['FEMA_9'] = ['g06', 'g32', 'g04']\n",
    "FEMA_subs['FEMA_10'] = ['g53', 'g41', 'g16']\n",
    "\n",
    "####################################\n",
    "# DataFrames to hold US, fema region, and state level results\n",
    "####################################\n",
    "\n",
    "# Dict to hold variable loadings\n",
    "# key will be [USA, Fema_region, stateid] depending on level of analysis\n",
    "varContrib = {}\n",
    "\n",
    "# National Score\n",
    "US_Sovi_Score = pd.DataFrame(index=US_All.Geo_FIPS,\n",
    "                             columns=['sovi', 'rank'])\n",
    "\n",
    "# In the FEMA_Region_Sovi_Score data frame ranks are BY FEMA REGION.\n",
    "# The data frame holds both the SOVI score and the county rank\n",
    "# This means that there should be 10 counties with rank 1 (one for each\n",
    "# FEMA Region)\n",
    "FEMA_Region_Sovi_Score = pd.DataFrame(index=US_All.Geo_FIPS,\n",
    "                                      columns=['sovi', 'rank', 'fema_region'])\n",
    "\n",
    "# Create New England conglomerate of states\n",
    "# These are the FIPS codes for the states wit hthe letter \"g\" appended\n",
    "US_All.loc[US_All.stateID.isin(['g23', 'g33', 'g25']), 'stateID'] = 'g23g33g25'\n",
    "\n",
    "# These are the states in the state level analysis\n",
    "stateList = ['g23g33g25', 'g36', 'g51', 'g13',\n",
    "             'g17', 'g48', 'g29', 'g46', 'g06', 'g16']\n",
    "\n",
    "# In the State_Sovi_Score data frame ranks are BY STATE.\n",
    "# The data frame holds both the SOVI score and the county rank\n",
    "# This means that there should be 10 counties with rank 1 (one for each\n",
    "# state in stateList)\n",
    "State_Sovi_Score = pd.DataFrame(\n",
    "    index=US_All.index[US_All.stateID.isin(stateList)],\n",
    "    columns=['sovi', 'rank', 'state_id'])\n",
    "\n",
    "#######################\n",
    "# Compute National SoVI\n",
    "#######################\n",
    "# compute SoVI\n",
    "inputData = US_All.drop(['Geo_FIPS', 'stateID'], axis=1, inplace=False)\n",
    "pca = SPSS_PCA(inputData, reduce=True, varimax=True)\n",
    "sovi_actual_us = pca.scores_rot.sum(1)\n",
    "sovi_actual_us = pd.DataFrame(\n",
    "    sovi_actual_us, index=US_All.Geo_FIPS, columns=['sovi'])\n",
    "# rank\n",
    "sovi_actual_us['rank'] = sovi_actual_us.rank(\n",
    "    method='average', ascending=False)\n",
    "US_Sovi_Score.update(sovi_actual_us)\n",
    "\n",
    "attrib_contribution_us = pca.weights_rot.sum(1)\n",
    "# Generate dictionary for all net loadings by variable for US\n",
    "varContrib['USA'] = zip(attr_names, attrib_contribution_us.tolist())\n",
    "\n",
    "# quick check of ranks max should equal number of counties in US\n",
    "try:\n",
    "    US_Sovi_Score['rank'].max() == len(US_All)\n",
    "except:\n",
    "    print(\"error in ranking check\")\n",
    "    raise\n",
    "\n",
    "# cleanup\n",
    "del inputData\n",
    "del sovi_actual_us\n",
    "del attrib_contribution_us\n",
    "\n",
    "\n",
    "######################\n",
    "# FEMA REGION SOVI\n",
    "######################\n",
    "for i in FEMA_subs:\n",
    "\n",
    "    # Subset FEMA subregion\n",
    "    FEMARegionData = US_All[US_All['stateID'].isin(FEMA_subs[i])]\n",
    "\n",
    "    # compute SoVI\n",
    "    inputData = FEMARegionData.drop(\n",
    "        ['Geo_FIPS', 'stateID'], axis=1, inplace=False)\n",
    "    pca = SPSS_PCA(inputData, reduce=True, varimax=True)\n",
    "    sovi_actual_fema = pca.scores_rot.sum(1)\n",
    "\n",
    "    # load into df for merge\n",
    "    sovi_actual_fema = pd.DataFrame(\n",
    "        sovi_actual_fema, index=FEMARegionData.index, columns=['sovi'])\n",
    "    # add fema region to df\n",
    "    sovi_actual_fema['fema_region'] = i\n",
    "    # rank\n",
    "    sovi_actual_fema['rank'] = sovi_actual_fema['sovi'].rank(\n",
    "        method='average', ascending=False)\n",
    "\n",
    "    FEMA_Region_Sovi_Score.update(sovi_actual_fema)\n",
    "\n",
    "    attrib_contribution_fema = pca.weights_rot.sum(1)\n",
    "\n",
    "    # Write attribute contribution output\n",
    "    # Generate dictionary for all net loadings by variable and region\n",
    "    varContrib[i] = zip(attr_names, attrib_contribution_fema.tolist())\n",
    "\n",
    "# cleanup\n",
    "del FEMARegionData\n",
    "del inputData\n",
    "del sovi_actual_fema\n",
    "del attrib_contribution_fema\n",
    "\n",
    "#############################################\n",
    "# State Analysis\n",
    "#############################################\n",
    "for st in stateList:\n",
    "    # Subset FEMA subregion\n",
    "    stateData = US_All[US_All.stateID == st]\n",
    "\n",
    "    # compute SoVI\n",
    "    inputData = stateData.drop(['Geo_FIPS', 'stateID'], axis=1, inplace=False)\n",
    "    pca = SPSS_PCA(inputData, reduce=True, varimax=True)\n",
    "    sovi_actual = pca.scores_rot.sum(1)\n",
    "    sovi_actual = pd.DataFrame(\n",
    "        sovi_actual, index=stateData.index, columns=['sovi'])\n",
    "    sovi_actual['state_id'] = st\n",
    "    # rank w/in state\n",
    "    sovi_actual['rank'] = sovi_actual['sovi'].rank(\n",
    "        method='average', ascending=False)\n",
    "    State_Sovi_Score.update(sovi_actual)\n",
    "    attrib_contribution = pca.weights_rot.sum(1)\n",
    "    varContrib[st] = zip(attr_names, attrib_contribution.tolist())\n",
    "\n",
    "# cleanup\n",
    "del stateData\n",
    "del inputData\n",
    "del sovi_actual\n",
    "del attrib_contribution\n",
    "\n",
    "###################################################\n",
    "# Make Var Contributions Data Frame\n",
    "###################################################\n",
    "variable_contributions = pd.DataFrame(index=attr_names)\n",
    "# for area in varContrib.iterkeys():\n",
    "for area in varContrib.keys():\n",
    "    variable_contributions[area] = [x for i, x in varContrib[area]]\n",
    "\n",
    "##########################################################################\n",
    "# Ranks w/ Geographic Extent\n",
    "# For each county rank within state for US, state, and fema_region sovis\n",
    "##########################################################################\n",
    "\n",
    "county_in_state_rank = pd.DataFrame(index=State_Sovi_Score.index,\n",
    "                                    columns=['state_sovi_rank', 'fema_region_sovi_rank', 'us_sovi_rank'])\n",
    "\n",
    "for st in stateList:\n",
    "    if st == 'g23g33g25':\n",
    "        # get all counties in the three NE states and rank for us\n",
    "        st_cty_scores = US_Sovi_Score.loc[\n",
    "            ['g23' in s for s in US_Sovi_Score.index], 'sovi']\n",
    "        st_cty_scores = st_cty_scores.append(\n",
    "            US_Sovi_Score.loc[['g33' in s for s in US_Sovi_Score.index], 'sovi'])\n",
    "        st_cty_scores = st_cty_scores.append(\n",
    "            US_Sovi_Score.loc[['g25' in s for s in US_Sovi_Score.index], 'sovi'])\n",
    "\n",
    "        county_in_state_rank.loc[st_cty_scores.index, 'us_sovi_rank'] = st_cty_scores.rank(method='average', ascending=False)\n",
    "\n",
    "        # get all counties in state and rank for fema region\n",
    "        st_cty_scores = FEMA_Region_Sovi_Score.loc[\n",
    "            ['g23' in s for s in FEMA_Region_Sovi_Score.index], 'sovi']\n",
    "        st_cty_scores = st_cty_scores.append(FEMA_Region_Sovi_Score.loc[\n",
    "                             ['g33' in s for s in FEMA_Region_Sovi_Score.index], 'sovi'])\n",
    "        st_cty_scores = st_cty_scores.append(FEMA_Region_Sovi_Score.loc[\n",
    "                             ['g25' in s for s in FEMA_Region_Sovi_Score.index], 'sovi'])\n",
    "\n",
    "        county_in_state_rank.loc[st_cty_scores.index, 'fema_region_sovi_rank'] = st_cty_scores.rank(method='average', ascending=False)\n",
    "\n",
    "        # county rank in state only sovi\n",
    "        county_in_state_rank.loc[st_cty_scores.index, 'state_sovi_rank'] = State_Sovi_Score.loc[State_Sovi_Score['state_id'] == 'g23g33g25', 'rank']\n",
    "\n",
    "    else:\n",
    "        st_cty_scores = US_Sovi_Score.loc[[st in s for s in US_Sovi_Score.index], 'sovi']\n",
    "        county_in_state_rank.loc[st_cty_scores.index, 'us_sovi_rank'] = st_cty_scores.rank(method='average', ascending=False)\n",
    "        # get all counties in state and rank for fema region\n",
    "        st_cty_scores = FEMA_Region_Sovi_Score.loc[[st in s for s in FEMA_Region_Sovi_Score.index], 'sovi']\n",
    "        county_in_state_rank.loc[st_cty_scores.index, 'fema_region_sovi_rank'] = st_cty_scores.rank(method='average', ascending=False)\n",
    "\n",
    "        # county rank in state only sovi\n",
    "        st_cty_scores = State_Sovi_Score.loc[State_Sovi_Score['state_id'] == st, 'rank']\n",
    "        county_in_state_rank.loc[st_cty_scores.index, 'state_sovi_rank'] = st_cty_scores\n",
    "\n",
    "#####################################################\n",
    "# Drop 1 Variable\n",
    "#####################################################\n",
    "USvarRanks = variable_contributions.USA.sort_values()\n",
    "dropLevels = USvarRanks.index\n",
    "\n",
    "#build multindex\n",
    "geoLevels = US_All.Geo_FIPS\n",
    "geoLabels = []\n",
    "for _ in range(len(dropLevels)):\n",
    "    geoLabels.extend(range(len(geoLevels)))\n",
    "dropLabels = np.repeat(range(len(dropLevels)), len(geoLevels))\n",
    "\n",
    "US_Drop1_Multi_Index = pd.MultiIndex(levels=[dropLevels, geoLevels],\n",
    "                                    labels=[dropLabels, geoLabels],\n",
    "                                    names=['DroppedVar', 'Geo_FIPS'])\n",
    "\n",
    "US_Drop1_NetContrib = pd.DataFrame(index=dropLevels, columns=dropLevels)\n",
    "\n",
    "US_SoVI_Drop1_Score = pd.DataFrame(index=US_Drop1_Multi_Index, columns=['sovi'])\n",
    "\n",
    "\n",
    "for j in dropLevels:\n",
    "    US_dropj = US_All.drop([j, 'Geo_FIPS', 'stateID'], axis=1, inplace=False)\n",
    "    pca = SPSS_PCA(US_dropj, reduce=True, varimax=True)\n",
    "    sovi_actual = pca.scores_rot.sum(1)\n",
    "    sovi_actual = pd.DataFrame(sovi_actual, index=geoLevels, columns=['sovi'])\n",
    "    US_SoVI_Drop1_Score.loc[j, 'sovi'] = sovi_actual.values\n",
    "    attrib_contribution = pd.DataFrame(data=pca.weights_rot.sum(1), index=US_dropj.columns)\n",
    "\n",
    "    attrib_contribution = attrib_contribution.transpose()\n",
    "    attrib_contribution.index = [j]\n",
    "    US_Drop1_NetContrib.loc[attrib_contribution.columns,j] = attrib_contribution.loc[j, :]\n",
    "\n",
    "\n",
    "# sort by rank order\n",
    "US_rank_order=abs(variable_contributions.USA).rank(method='average',ascending=False).sort_values().index # original rank order\n",
    "US_Drop1_NetContrib=US_Drop1_NetContrib.ix[US_rank_order] # sort rows\n",
    "US_Drop1_NetContrib=US_Drop1_NetContrib.ix[:,US_rank_order] # sort columns\n",
    "\n",
    "# ranked version of the drop 1 variable table\n",
    "US_Drop1_NetContrib_ranks=US_Drop1_NetContrib.copy()\n",
    "US_Drop1_NetContrib_ranks=US_Drop1_NetContrib_ranks.apply(lambda x: abs(x).rank(method='average',ascending=False)) # convert absolute scores to ranks\n",
    "US_Drop1_NetContrib_ranks=US_Drop1_NetContrib_ranks.ix[US_rank_order] # sort rows\n",
    "US_Drop1_NetContrib_ranks=US_Drop1_NetContrib_ranks.ix[:,US_rank_order] # sort columns\n",
    "\n",
    "######################\n",
    "# CORRELATIONS\n",
    "######################\n",
    "state_corrs = pd.DataFrame(index = stateList, columns = ['spearman_r_st_fema', 'pvalue_st_fema', 'spearman_r_st_us', 'pvalue_st_us'])\n",
    "for st in stateList:\n",
    "  if st == 'g23g33g25':\n",
    "    multi_state_data_tmp = county_in_state_rank.ix[['g23' in s for s in county_in_state_rank.index], ]\n",
    "    multi_state_data_tmp = multi_state_data_tmp.append(\n",
    "      county_in_state_rank.ix[['g25' in s for s in county_in_state_rank.index], ])\n",
    "    multi_state_data_tmp = multi_state_data_tmp.append(\n",
    "      county_in_state_rank.ix[['g33' in s for s in county_in_state_rank.index], ])\n",
    "    st_fema_spearman = spearmanr(multi_state_data_tmp[['state_sovi_rank', 'fema_region_sovi_rank']])\n",
    "    st_us_spearman = spearmanr(multi_state_data_tmp[['state_sovi_rank', 'us_sovi_rank']])\n",
    "    state_corrs.loc['g23g33g25', ] = [st_fema_spearman[0], st_fema_spearman[1], st_us_spearman[0], st_us_spearman[1]]\n",
    "  else:\n",
    "    st_fema_spearman = spearmanr(county_in_state_rank.ix[[st in s for s in county_in_state_rank.index], ['state_sovi_rank', 'fema_region_sovi_rank']])\n",
    "    st_us_spearman = spearmanr(county_in_state_rank.ix[[st in s for s in county_in_state_rank.index], ['state_sovi_rank', 'us_sovi_rank']])\n",
    "    state_corrs.loc[st, ] = [st_fema_spearman[0], st_fema_spearman[1], st_us_spearman[0], st_us_spearman[1]]\n",
    "\n",
    "################\n",
    "# DROP ONE PLACE\n",
    "################\n",
    "\n",
    "# df containing county names - no need for the geometr#\n",
    "# county_names=pd.DataFrame(gpd.read_file(os.path.join(s#path,'USA_Counties_500k.shp('../data/\n",
    "county_names=pd.read_csv(os.path.join(ipath,'county_names.csv'),index_col=0,encoding='latin-1')\n",
    "\n",
    "# ##### State (California)\n",
    "print('\\nDrop One Place: State\\n')\n",
    "# spearman rank correlations\n",
    "ca_cors=dropCors(US_All,State_Sovi_Score,'g06')\n",
    "\n",
    "# drop run with minimum rank correlation\n",
    "cad=ca_cors[ca_cors==min(ca_cors)].index.values[0]\n",
    "\n",
    "# rank change table with minimum rank correlation\n",
    "ca_rchg=rankChgTable(inputs=US_All,scores=State_Sovi_Score,obs_names=county_names,subset='g06',drop=cad,cor=True,top=10)\n",
    "\n",
    "# rank quantile moves with minimum rank correlation\n",
    "ca_quint_moves=rankQuantileMoves(inputs=US_All,scores=State_Sovi_Score,subset='g06',drop=cad)\n",
    "\n",
    "# ##### FEMA 9: California and surrounding states (includes Hawaii)\n",
    "print('Drop One Place: FEMA\\n')\n",
    "\n",
    "f9_cors=dropCors(US_All,FEMA_Region_Sovi_Score,'FEMA_9')\n",
    "\n",
    "# obs that decreases the correlation most when dropped\n",
    "f9cd=f9_cors[f9_cors==min(f9_cors)].index.values[0]\n",
    "\n",
    "f9_rchg=rankChgTable(inputs=US_All,scores=FEMA_Region_Sovi_Score,obs_names=county_names,subset='FEMA_9',drop=f9cd,cor=True,top=10)\n",
    "\n",
    "# rank quantile moves\n",
    "f9_quint_moves=rankQuantileMoves(inputs=US_All,scores=FEMA_Region_Sovi_Score,subset='FEMA_9',drop=f9cd)\n",
    "\n",
    "# ### Full USA\n",
    "print('Drop One Place: USA\\n')\n",
    "\n",
    "us_cors=dropCors(US_All,US_Sovi_Score)\n",
    "\n",
    "# obs that decreases the correlation most when dropped\n",
    "uscd=us_cors[us_cors==min(us_cors)].index.values[0]\n",
    "\n",
    "us_rchg=rankChgTable(inputs=US_All,scores=US_Sovi_Score,obs_names=county_names,drop=uscd,cor=True,top=10)\n",
    "\n",
    "# rank quantile moves\n",
    "us_quint_moves=rankQuantileMoves(inputs=US_All,scores=US_Sovi_Score,drop=uscd)\n",
    "print('\\n')\n",
    "\n",
    "# cleanup\n",
    "del multi_state_data_tmp\n",
    "#####################################################\n",
    "# OUTPUT TABLES\n",
    "#####################################################\n",
    "US_Sovi_Score.to_csv(os.path.join(outPath, 'output', 'US_Sovi_Score.csv'))\n",
    "\n",
    "# In the FEMA_Region_Sovi_Score data frame ranks are BY FEMA REGION.\n",
    "# The data frame holds both the SOVI score and the county rank\n",
    "# This means that there should be 10 counties with rank 1 (one for each\n",
    "# FEMA Region)\n",
    "FEMA_Region_Sovi_Score.to_csv(os.path.join(\n",
    "    outPath, 'output', 'FEMA_Region_Sovi_Score.csv'))\n",
    "\n",
    "# In the State_Sovi_Score data frame ranks are BY STATE.\n",
    "# The data frame holds both the SOVI score and the county rank\n",
    "# This means that there should be 10 counties with rank 1 (one for each\n",
    "# state in stateList)\n",
    "State_Sovi_Score.to_csv(os.path.join(\n",
    "    outPath, 'output', 'State_Sovi_Score.csv'))\n",
    "\n",
    "# County rank within state for US, state, and fema_region sovis\n",
    "county_in_state_rank.to_csv(os.path.join(\n",
    "    outPath, 'output', 'County_in_State_Rank.csv'))\n",
    "\n",
    "# Variable contributions for sovis at all geographic extents\n",
    "variable_contributions.to_csv(os.path.join(\n",
    "    outPath, 'output', 'variable_contributions.csv'))\n",
    "\n",
    "# Net contribution of variables after dropping a variable\n",
    "US_Drop1_NetContrib.to_csv(os.path.join(\n",
    "    outPath, 'output', 'US_Drop1_NetContrib_raw.csv'))\n",
    "\n",
    "# rank of variables after dropping a variable\n",
    "US_Drop1_NetContrib_ranks.to_csv(os.path.join(\n",
    "    outPath, 'output', 'US_Drop1_NetContrib_ranks.csv'))\n",
    "\n",
    "# Correlation of ranks\n",
    "state_corrs.to_csv(os.path.join(\n",
    "    outPath, 'output', 'state_fema_us_rank_correlations.csv'))\n",
    "\n",
    "# Drop 1 place\n",
    "ca_rchg.to_csv(os.path.join(outPath,'output','drop1_place_state_rank_change_ca.csv'))\n",
    "ca_quint_moves.to_csv(os.path.join(outPath,'output','drop1_place_state_quint_moves_ca.csv'))\n",
    "f9_rchg.to_csv(os.path.join(outPath,'output','drop1_place_fema_rank_change_fema9.csv'))\n",
    "f9_quint_moves.to_csv(os.path.join(outPath,'output','drop1_place_fema_quint_moves_fema9.csv'))\n",
    "us_rchg.to_csv(os.path.join(outPath,'output','drop1_place_usa_rank_change.csv'))\n",
    "us_quint_moves.to_csv(os.path.join(outPath,'output','drop1_place_usa_quint_moves.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
