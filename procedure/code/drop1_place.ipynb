{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2822739-8f2f-4429-8aad-f005f7e9a341",
   "metadata": {},
   "source": [
    "# Runs !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64d43ca3-a5cd-432c-b39b-a77390bbb0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = {\n",
    "    \"id\": [1,2,3],\n",
    "    \"calories\": [420, 380, 390],\n",
    "    \"duration\": [50, 40, 45]\n",
    "}\n",
    "data1 = pd.DataFrame(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73b283f3-f875-4191-8c98-15eb11f23845",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data1.drop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "795227dd-0920-40e7-ae1a-1dd0bbc82121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>calories</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>420</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>380</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>390</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  calories  duration\n",
       "0   1       420        50\n",
       "1   2       380        40\n",
       "2   3       390        45"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5814c2e8-3f4d-49d1-b653-3389784a3434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>calories</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>420</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>390</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  calories  duration\n",
       "0   1       420        50\n",
       "2   3       390        45"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "070d022b-2bc7-4464-95d9-9a1d2775c5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import zscore as ZSCORE\n",
    "from scipy.stats import rankdata\n",
    "from scipy.stats import spearmanr\n",
    "import mapclassify\n",
    "\n",
    "# sovi compute script\n",
    "# import sys\n",
    "# sys.path.append(os.path.join(os.getcwd(),'code'))\n",
    "%run 'spss_pca.ipynb'\n",
    "# from spss_pca import SPSS_PCA\n",
    "# import compute_sovis\n",
    "\n",
    "# outPath=compute_sovis.outPath\n",
    "\n",
    "def dropAny(inputs,scores,drop=1,subset=None,netContrib=None,return_drop_rank=False):\n",
    "\n",
    "    \"\"\"\n",
    "    inputs, the input variables, i.e. compute_sovis.USA_All\n",
    "\n",
    "    scores, the SoVI outputs containing scores and ranks i.e. compute_sovis.USA_Sovi_Score\n",
    "\n",
    "    subset: list of GEOIDs for subset (use for FEMA region or state)\n",
    "\n",
    "    netContrib: i.e. compute_sovis.variable_ranks\n",
    "    \"\"\"\n",
    "\n",
    "    if not subset is None:\n",
    "        scores=scores[scores[scores.columns[len(scores.columns)-1]].astype('str').str.contains(subset)] # scores for region id\n",
    "        inputs=inputs[inputs.index.isin(scores[scores.columns[len(scores.columns)-1]].index)] # inputs for subset\n",
    "\n",
    "    # the data without no 1\n",
    "    drop_no1=inputs.drop(drop)\n",
    "\n",
    "    # preserve GEOIDs as an index\n",
    "    # for computed SoVI\n",
    "    geoLevels=drop_no1.Geo_FIPS\n",
    "\n",
    "    #Compute drop \"number one\"\n",
    "    pca = SPSS_PCA(drop_no1.drop(['Geo_FIPS', 'stateID'], axis = 1, inplace = False).values, reduce=True, varimax=True)\n",
    "    sovi_actual = pca.scores_rot.sum(1)\n",
    "    sovi_actual = pd.DataFrame(sovi_actual, index=geoLevels, columns=['sovi'])\n",
    "    drop1p_score = sovi_actual.values # SoVI score\n",
    "\n",
    "    if netContrib is None: # no net contrib var's specified, compute county ranks\n",
    "\n",
    "        # preserve the original county ranks\n",
    "        # also for computing change in rank...\n",
    "        orig_rank=scores.drop(drop)['rank']\n",
    "\n",
    "        # add SoVI ranks for run\n",
    "        drop1p_rank = pd.Series([i[0] for i in sovi_actual.values],index=geoLevels).rank(ascending=False)\n",
    "\n",
    "        obs_rchg_drop1=pd.DataFrame({'orig_rank':orig_rank,'drop1p_rank':drop1p_rank},index=orig_rank.index)\n",
    "        obs_rchg_drop1=obs_rchg_drop1.apply(lambda x: x.astype('int'),axis=1) # ensure all ints\n",
    "        obs_rchg_drop1['rank_chg']=obs_rchg_drop1.orig_rank-obs_rchg_drop1.drop1p_rank\n",
    "\n",
    "        return obs_rchg_drop1\n",
    "\n",
    "    else: # net contribution\n",
    "\n",
    "        #variable rank using absolute value\n",
    "        rankContrib = abs(netContrib).apply(rankdata, axis=0, method='average')\n",
    "        rankContrib = (28-rankContrib) + 1\n",
    "\n",
    "        #Construct table to hold the results of the drop one analysis\n",
    "        #Sort variable list based on importance rank.\n",
    "        if not subset:\n",
    "            varRanks = rankContrib['USA'].copy() #have to make a copy to sort index\n",
    "            varRanks.sort('USA')\n",
    "        else:\n",
    "            varRanks = rankContrib[subset].copy() #have to make a copy to sort index\n",
    "            varRanks.sort(subset)\n",
    "\n",
    "        # recompute net contribution for drop no1\n",
    "        Drop1_NetContrib = pd.Series(data=pca.weights_rot.sum(1), index=drop_no1.columns.drop(['Geo_FIPS', 'stateID']))\n",
    "        Drop1_NetContrib = Drop1_NetContrib.transpose()\n",
    "        Drop1_NetContrib=Drop1_NetContrib.convert_objects(convert_numeric=True)\n",
    "        Drop1_NetContrib = Drop1_NetContrib.apply(lambda x: np.round(x, 2))\n",
    "        Drop1_NetContrib = Drop1_NetContrib.rank(ascending=False)\n",
    "\n",
    "        Drop1_NetContrib=Drop1_NetContrib[varRanks.index] # sort values by original index ranking\n",
    "\n",
    "        nc_chg_drop1p=pd.DataFrame({'orig_rank':varRanks,'drop1p_rank':Drop1_NetContrib})\n",
    "        nc_chg_drop1p=nc_chg_drop1p.apply(lambda x: x.astype('int'),axis=1) # ensure all ints\n",
    "        nc_chg_drop1p['rank_chg']=nc_chg_drop1p.orig_rank-nc_chg_drop1p.drop1p_rank\n",
    "\n",
    "        return nc_chg_drop1p\n",
    "\n",
    "def rankChgTable(inputs,scores,obs_names,subset=None,top=5,cor=False,drop=1,verbose=True):\n",
    "\n",
    "    dropany_result=dropAny(inputs=inputs,scores=scores,subset=subset,drop=drop)\n",
    "\n",
    "    # ensure GEOID column in place\n",
    "    # assumes missing GEOID values stored in df index\n",
    "    if not 'geoFIPS' in dropany_result:\n",
    "        dropany_result['geoFIPS']=dropany_result.index\n",
    "\n",
    "    # merge dropany results with obs names\n",
    "    rctab=dropany_result.merge(obs_names, left_on='geoFIPS', right_on=\"GEOID\")\n",
    "\n",
    "    # print the spearman rank correlation if specified\n",
    "    if cor:\n",
    "        spearcor=spearmanr(rctab.drop1p_rank,rctab.orig_rank)\n",
    "        if verbose:\n",
    "            print(\"Spearman Rank Correlation: \"+str(np.round(spearcor[0],5)),\"\\np-value: \"+str(np.round(spearcor[1],4)))\n",
    "            print('\\n')\n",
    "\n",
    "    # dropped obs rank\n",
    "    drop_co=obs_names[obs_names.GEOID.str.contains(drop)]\n",
    "    drop_co['orig_rank']=scores.loc[drop]['rank']\n",
    "\n",
    "    # assemble table for original ranks\n",
    "    orrk=rctab[rctab.orig_rank<=top].loc[:,['geoFIPS','orig_rank','NAME']]\n",
    "\n",
    "    if int(drop_co.orig_rank)<=top: # append dropped obs to table if top-ranked\n",
    "        orrk = pd.concat([drop_co, orrk])\n",
    "\n",
    "    orrk=orrk.sort_values('orig_rank')\n",
    "    orrk['Top_Orig']=orrk.NAME+\" (\"+orrk.orig_rank.astype('int').astype('str')+\")\"\n",
    "    orrk.index=[i+1 for i in range(0,top)]\n",
    "    orrk.loc[:,['NAME','Top_Orig']]\n",
    "\n",
    "    # assemble table for dropany ranks\n",
    "    d1rk=rctab[rctab.drop1p_rank<=top].loc[:,['geoFIPS','drop1p_rank','orig_rank','NAME']].sort_values('drop1p_rank')\n",
    "    d1rk['Top_dropany']=d1rk.NAME+\" (\"+d1rk.orig_rank.astype('int').astype('str')+\")\"\n",
    "    d1rk.index=[i+1 for i in range(0,top)]\n",
    "    d1rk.loc[:,['NAME','Top_dropany']]\n",
    "\n",
    "    # return the tables combined\n",
    "    return pd.DataFrame({'All_Counties':orrk.Top_Orig,'Drop_1':d1rk.Top_dropany})\n",
    "\n",
    "# wrap to a function\n",
    "def dropCors(inputs,scores,subset=None):\n",
    "\n",
    "    cors=[]\n",
    "\n",
    "    if subset is None:\n",
    "        geo_idx=scores.index.values\n",
    "    else:\n",
    "        geo_idx=scores[scores[scores.columns[len(scores.columns)-1]].astype('str').str.contains(subset)].index.values\n",
    "\n",
    "    for i in geo_idx:\n",
    "        drop_i=dropAny(inputs=inputs,scores=scores,subset=subset,drop=i)\n",
    "        cor=spearmanr(drop_i.drop1p_rank,drop_i.orig_rank)\n",
    "        cors.append(cor[0])\n",
    "\n",
    "    return pd.Series(cors,index=geo_idx)\n",
    "\n",
    "## function for plotting rank quantile moves\n",
    "\n",
    "def rankQuantileMoves(inputs,scores,drop,subset=None,verbose=True):\n",
    "    da=dropAny(inputs=inputs,scores=scores,subset=subset,drop=drop)\n",
    "    if verbose:\n",
    "        print(mapclassify.Quantiles(da.orig_rank)) # quantile breaks key\n",
    "        print('\\n')\n",
    "    r0=mapclassify.Quantiles(da.orig_rank).yb\n",
    "    r1=mapclassify.Quantiles(da.drop1p_rank).yb\n",
    "    moves_raw=pd.DataFrame({'r0':r0,'r1':r1}).groupby(['r0','r1']).size().unstack(fill_value=0)\n",
    "    return np.round(moves_raw.apply(lambda x: x/sum(x),axis=1),2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:RPl-Spielman-2020]",
   "language": "python",
   "name": "conda-env-RPl-Spielman-2020-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
